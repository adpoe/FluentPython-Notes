{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency with asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare vs Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Thread(Thread-4, initial)>\n",
      "| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b- thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b           \b\b\b\b\b\b\b\b\b\b\bAnswer: 42\n"
     ]
    }
   ],
   "source": [
    "# spinner_thread.py\n",
    "\n",
    "# credits: Adapted from Michele Simionato's\n",
    "# multiprocessing example in the python-list:\n",
    "# https://mail.python.org/pipermail/python-list/2009-February/538048.html\n",
    "\n",
    "# BEGIN SPINNER_THREAD\n",
    "import threading\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "def spin(msg, done):  # <2>\n",
    "    write, flush = sys.stdout.write, sys.stdout.flush\n",
    "    for char in itertools.cycle('|/-\\\\'):  # <3>\n",
    "        status = char + ' ' + msg\n",
    "        write(status)\n",
    "        flush()\n",
    "        write('\\x08' * len(status))  # <4>\n",
    "        if done.wait(.1):  # <5>\n",
    "            break\n",
    "    write(' ' * len(status) + '\\x08' * len(status))  # <6>\n",
    "\n",
    "\n",
    "def slow_function():  # <7>\n",
    "    # pretend waiting a long time for I/O\n",
    "    time.sleep(3)  # <8>\n",
    "    return 42\n",
    "\n",
    "\n",
    "def supervisor():  # <9>\n",
    "    done = threading.Event()\n",
    "    spinner = threading.Thread(target=spin,\n",
    "                               args=('thinking!', done))\n",
    "    print('spinner object:', spinner)  # <10>\n",
    "    spinner.start()  # <11>\n",
    "    result = slow_function()  # <12>\n",
    "    done.set()  # <13>\n",
    "    spinner.join()  # <14>\n",
    "    return result\n",
    "\n",
    "\n",
    "def main():\n",
    "    result = supervisor()  # <15>\n",
    "    print('Answer:', result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "# END SPINNER_THREAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now with an Asyncio coroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object:  <Task pending coro=<spin() running at <ipython-input-4-f05f121b810c>:5>>\n",
      "| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b/ thinking!\b\b\b\b\b\b\b\b\b\b\b= thinking!\b\b\b\b\b\b\b\b\b\b\b\\ thinking!\b\b\b\b\b\b\b\b\b\b\b| thinking!\b\b\b\b\b\b\b\b\b\b\b           \b\b\b\b\b\b\b\b\b\b\bAnswer:  42\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "@asyncio.coroutine\n",
    "def spin(msg):\n",
    "    write, flush = sys.stdout.write, sys.stdout.flush\n",
    "    for char in itertools.cycle('|/=\\\\'):\n",
    "        status = char + ' ' + msg\n",
    "        write(status)\n",
    "        flush()\n",
    "        write('\\x08' * len(status))\n",
    "        try:\n",
    "            yield from asyncio.sleep(.1)\n",
    "            # using the combo of yield from and asyncio.sleep\n",
    "            # we can sleep without blocking the event loop\n",
    "        except asyncio.CancelledError: \n",
    "            break\n",
    "    write(' ' * len(status) + '\\x08' * len(status))\n",
    "\n",
    "@asyncio.coroutine\n",
    "def slow_function():\n",
    "    # pretend waiting a long time for I/O\n",
    "    yield from asyncio.sleep(3) #  handles control flow to the main loop,\n",
    "    # and wil resume the coroutine after the sleep delay\n",
    "    return 42\n",
    "\n",
    "@asyncio.coroutine\n",
    "def supervisor():\n",
    "    # asyncio.async schedules the the spin coro to run\n",
    "    # wrapping it in a Task object, which is returned immediatly\n",
    "    spinner = asyncio.async(spin('thinking!'))  \n",
    "    print('spinner object: ', spinner) # display the task object\n",
    "    result = yield from slow_function() # drive the slow function\n",
    "    # when that is done, we get the returned value\n",
    "    # meanwhile the event loop will continue running because slow_function\n",
    "    # ulimately uses yield from asyncio.sleep(3) to hand control\n",
    "    # back to the main loop\n",
    "    spinner.cancel() # ends the coro\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    loop = asyncio.get_event_loop()  # get a ref to the event loop\n",
    "    result = loop.run_until_complete(supervisor())  # drive the supervisor\n",
    "    # to completion. The return value of the coor is the return value\n",
    "    # of this call\n",
    "    print('Answer: ', result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Never use time.sleep(...) in asyncio coro's unless you want\n",
    "to block the main thread, therefore freezing the event loop \n",
    "and prob whole application.... \n",
    "\n",
    "If coro must spend time doing nothing, use: yield from asyncio.sleep(DELAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick coro experiment code\n",
    "import asyncio\n",
    "def run_sync(coro_or_future):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(coro_or_future)\n",
    "\n",
    "a = run_sync(some_coroutine())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with asyncio and aiohttp\n",
    "asyncio supports TCP and UDP directly.\n",
    "\n",
    "For HTTP or any other protocol, we need 3rd party packages.\n",
    "\n",
    "aiohttp is the one to use or asyncio HTTP clients right now.\n",
    "\n",
    "Idea for below example:\n",
    "- Single threaded program where a main-loop activates queued coroutines one by one\n",
    "- Each coroutine advances a few steps, then yields control back to the main loop, which activates the next coroutine in the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "from flags import BASE_URL, save_flag, show, main\n",
    "\n",
    "@asyncio.coroutine\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = yield from aiohttp.request('GET', url)  # blocking operations\n",
    "    # are implemented via coroutines, and this code delegates to them \n",
    "    # via `yield from` so they run asynchronously\n",
    "    image = yield from resp.read()   # reading response content\n",
    "    # is a _separate_ async operation\n",
    "    return image\n",
    "\n",
    "@asyncio.coroutine\n",
    "def download_one(cc):\n",
    "    image = yield from get_flag(cc)  \n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    loop = asyncio.get_event_loop()  # get a refernce to \n",
    "    # the underlying event loop implementation\n",
    "    to_do = [download_one(cc) for cc in sorted(cc_list)] # build a list\n",
    "    # of generator objects by calling the download_one function\n",
    "    # once for each flag being retrieved\n",
    "    wait_coro = asyncio.wait(to_do)  # despite its name, wait is not\n",
    "    # a blocking function... It's a coroutine that completes when\n",
    "    # all the coroutines passed to it are done... (that's the\n",
    "    # default behavior of wait)\n",
    "    res, _ = loop.run_until_complete(wait_coro)  # Execute the event loop\n",
    "    # until wait_coro is done.  this is where the script will block \n",
    "    # while the event loop runs. We ignore the second item returned \n",
    "    # by run_until_complete. \n",
    "    \n",
    "    return len(res)\n",
    "\n",
    "# if name is main... run it.. but skipping for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Notes\n",
    "The asyncio.wait(...) coroutine accepts an iterable of futures or coroutines; wait wraps each Coroutine in a Task.\n",
    "\n",
    "This means all objects managed by wait becomes instances of Future... And because is is a coro function, calling wait(...) returns a coro/generator tha; this is waht the wait_cor variable holds. \n",
    "\n",
    "To drive the coro, we pass to to loop.run_until_complete(...)\n",
    "\n",
    "loop.run_until_complete(...) accepts a future or a coroutine. If it gets a coroutine, run_until complete wraps it in a task, similar to what wait does. \n",
    "\n",
    "Coroutines, Tasks, and Futures are ALL driven by yield from....\n",
    "\n",
    "Upon completion run_until_complete returns a 2-tuple. First item is set of completed futures. Second item is uncompleted ones.\n",
    "\n",
    "To use asyncio, must replace all functions that hit network with an async version that is invoked by a yield from; this ensures control is given back to the event loop.\n",
    "\n",
    "\n",
    "##### Trick\n",
    "When reasoning about coroutines, ignore the `yield from`, and read it as if it were regular sequential code. The `yield from` version does the same thing, but blocks and does the work asynchronously. (a little more complicated than that, but point is: don't get hung up on the yield from. think about what the code is doing)\n",
    "\n",
    "\n",
    "#### Key Points\n",
    "- Outermost function must be a caller that is NOT a coroutine, and uses next(...) or send(...)\n",
    "- Innermost subgenerator must be a simple generator that uses yield, or an iterable object..\n",
    "- In between, we can chain as many generators as we want. And that's a coroutine\n",
    "\n",
    "#### Asyncio specifc\n",
    "- For asyncio, an API call doe the driving (loop.run_until_complete(...) in this case)\n",
    "- Must end with an asycio coroutine function or method (e.g. - yield from asyncio.sleep(...) or the aiohttp request that we used here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using asyncio.as_completed\n",
    "\n",
    "Get results AS they complete, NOT once ALL are complete.\n",
    "\n",
    "This is asyncio equivalent to the as_completed generator function used in the threadpool example, with progress bar.\n",
    "\n",
    "Semaphore() object holds an internal counter that is decremented whenever we call acquire() and incremented whenever we call release() on the samephare...\n",
    "\n",
    "Here, we use Semaphore as a conntext manager in this block...\n",
    "\n",
    "The snippet guarantess that no more than concur_req instances of get_flags coros will be started at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import collections\n",
    "\n",
    "import aiohttp\n",
    "from aiohttp import web\n",
    "import tqdm\n",
    "\n",
    "# and reuse some functions from the flags download example\n",
    "\n",
    "# default set low to avoid errors from remote site, such as\n",
    "# 503 - Service Temporarily Unavailable\n",
    "DEFAULT_CONCUR_REQ = 5\n",
    "MAX_CONCUR_REQ = 10000\n",
    "\n",
    "class FetchError(Exception):  # use this custom exception to wrap HTTP\n",
    "    # or other network exceptions, and carry the country code for reporting\n",
    "    def __init__(self, country_code):\n",
    "        self.country_code = country_code\n",
    "        \n",
    "    @asyncio.coroutine\n",
    "    def get_flag(base_url, cc): # get_flag will either return the bytes of\n",
    "        # the image DL'd o, or raise web.HTTPNotFound if resp is 404\n",
    "        # or raise an aiohttp.HttpProcessingError for other status codes\n",
    "        url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower())\n",
    "        resp = yield from aiohttp.requet('GET', url)\n",
    "        if resp.status == 200:\n",
    "            image = yield from resp.read()\n",
    "            return read\n",
    "        elif resp.status == 404:\n",
    "            raise web.HTTPNotFound()\n",
    "        else:\n",
    "            raise aiohttp.HttpProcessingError(\n",
    "                code=resp.status, message=resp.reason,\n",
    "                headers=resp.headers)\n",
    "    \n",
    "    @asyncio.coroutine\n",
    "    def download_one(cc, base_url, semaphore, verbose):\n",
    "        try:\n",
    "            with (yield from semaphore):  # the semaphore arg is an \n",
    "                # instance of asyncio.Semaphore\n",
    "                image = yield from get_flag(base_url, cc) # a semaphore\n",
    "                # is used as a context manager in a yield from expression\n",
    "                # so that the system as a whole is not blocked\n",
    "                # only this coroutine is blocked while the semaphore\n",
    "                # counter is at the maximum allowed number\n",
    "                \n",
    "                # also note:  when this with statement exits, the\n",
    "                # semaphore counter is decremented, unblocking some other \n",
    "                # coroutine instance that may be waiting for the same\n",
    "                # semaphore object\n",
    "                except web.HTTPNotFound:\n",
    "                    status = HTTPStatus.no_found\n",
    "                    msg = 'not found'\n",
    "                except Exception as exc:\n",
    "                    raise FetchError(cc) from exc # Uses the exception\n",
    "                    # chaining synatx from PEP 3134\n",
    "                else:\n",
    "                    save_flag(image, cc.lower() + '.gif')  # fn saves\n",
    "                    # the flag image to disk\n",
    "                    status = HTTPStatus.ok\n",
    "                    msg = 'OK'\n",
    "                \n",
    "                if verbose and msg:\n",
    "                    print(cc, msg)\n",
    "                \n",
    "                return Results(status, cc)\n",
    "    \n",
    "    @asyncio.coroutine\n",
    "    def downloader_coro(cc_list, base_url, verbose, concur_req):\n",
    "        # receives same args as download_many, but cannot be invoked\n",
    "        # direcrly from main because it's a coor\n",
    "        counter = collections.Counter()\n",
    "        semaphore = asyncio.Semaphore(concur_req)  # allows up to\n",
    "        # concur_req active coroutines using this same semaphore\n",
    "        to_do = [download_one(cc, base_url, semaphore, verbose)\n",
    "                 for cc in sorted(cc_list)]  # Create a list of coro\n",
    "        # objects, one per call, to the downlone_one_function\n",
    "        to_do_iter = asyncio.as_completed(to_do)  # get an iterator \n",
    "        # that will return futures as they are done\n",
    "        if not verbose:\n",
    "            to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list)) \n",
    "            # wrap iter in tqdm function to display progresss\n",
    "        for future in to_do_iter:\n",
    "            try:\n",
    "                res = yield from future  # iteraten over the comleted futrs\n",
    "            except FetchError as exc:\n",
    "                country_code = exc.country_code  \n",
    "                try:\n",
    "                    error_msg = exc.__cause__.args[0]  # try to retrieve\n",
    "                    # original msg from the exception __cause__\n",
    "                except IndexError:\n",
    "                    error_msg = exc.__cause__.__class__.__name___\n",
    "                if verbose and error_msg:\n",
    "                    msg = '*** Error for {} {}'\n",
    "                    print(msg.format(country_code, error_msg))\n",
    "                status = HTTPStatus.error\n",
    "            else:\n",
    "                status = res.status\n",
    "                \n",
    "            counter[status] += 1  # tally outcomes\n",
    "        return counter\n",
    "    \n",
    "    def download_many(cc_list, base_url, verbose, concur_req):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        coro = downloader_coro(cc_list, base_url, verbose, concur_req)\n",
    "        counts = loop.run_until_complete(coro)  # download many simply\n",
    "        # instantiates the coro and passes it to the event loop\n",
    "        # with run_until_complete\n",
    "        loop.close()  # when all work done, shut down event loop\n",
    "        # and return counts\n",
    "        \n",
    "        return counts\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Executor to Avoid Blocking in the Event Loop\n",
    "\n",
    "Only a few lines need to change. Prevents blocking for disk I/O. Can save millions of CPU cycles. (Still a fraction of a second, but it's a lot...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@asyncio.coroutine\n",
    "def download_one(cc, base_url, semaphore, verbose):\n",
    "    try:\n",
    "        with (yield from semaphore):\n",
    "            image = yield from get_flag(base_url, cc)\n",
    "        except web.HTTPNotFound:\n",
    "            status = HTTPStatus.not_found\n",
    "            msg = 'not found'\n",
    "        except Except as exc:\n",
    "            raise FetchError(cc) from exc\n",
    "        else:\n",
    "            loop = asycio.get_event_loop() # get a ref to\n",
    "            # the event loop object\n",
    "        \n",
    "        loop.run_in_executor(None,  # first arg is an executor instance,\n",
    "                            # if NOne, the default thpool exec of the \n",
    "                            # event loop is used\n",
    "                    save_flag, image, cc.lower() + '.gif') \n",
    "        \n",
    "        if verbose and msg:\n",
    "            print(cc, msg)\n",
    "        \n",
    "        return Result(status, cc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Callbacks to Futures to Coroutines\n",
    "\n",
    "Instead of callbacks, use coroutines. yield, and then when result is ready, activate coro with a .send() call. \n",
    "\n",
    "We we even get to maintain context all withon one function body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coroutines and yield enable asynchronous programming w/o callbacks\n",
    "@asyncio.coroutine\n",
    "def three_stages(request1):\n",
    "    response1 = yield from api_call1(request1)\n",
    "    # stage 1\n",
    "    request2 = step1(response1)\n",
    "    response2 = yield from api_call2(request2)\n",
    "    # stage 2\n",
    "    request3 = step2(response2)\n",
    "    response3 = yield from api_call3(request3)\n",
    "    # stage 3\n",
    "    step3(response3)\n",
    "\n",
    "loop.create_task(three_stages(request1))  # must explicitly schedl selctn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT:  You must explicitly schedule exeution of the coro with the event loop, or activate it using yield from in another coroutine that is scheduled for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
