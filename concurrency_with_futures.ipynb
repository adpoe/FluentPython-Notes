{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency with Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequential download script, used as a baseline\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BEGIN FLAGS_PY\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests  # <1>\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "\n",
    "def save_flag(img, filename):  # <5>\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "\n",
    "def get_flag(cc):  # <6>\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def show(text):  # <7>\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download_many(cc_list):  # <8>\n",
    "    for cc in sorted(cc_list):  # <9>\n",
    "        image = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "\n",
    "    return len(cc_list)\n",
    "\n",
    "\n",
    "def main(download_many):  # <10>\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)  # <11>\n",
    "# END FLAGS_PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with Concurrent futures\n",
    "\n",
    "Main features are the ThreadPoolExecutor and the ProcessPoolExecutor classes. \n",
    "\n",
    "These implement an interface that allows you to submit callables for execution in different threads or processes, respectively. \n",
    "\n",
    "The classes manage an internal pool of worker threads or processes, and a queue of tasks to be executed. But the interface is very high level and doesn't need to known about any of the details; at least for a simple case like this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reuse some functions from before, as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WORKERS = 20  # max num threads allowed in our threadpool\n",
    "\n",
    "# function to download one image.\n",
    "# this is what each thread will execute\n",
    "def download_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = mine(MAX_WORKERS, len(cc_list)) # don't use more workers than imgs\n",
    "    # instantiate the thpool exec with the spec'd # of worker threads\n",
    "    # the executor.__exit__ method will call executor.shutdown(wait=True)\n",
    "    # which will block until ALL threads are done\n",
    "    with futures.ThreadPoolExecutor(workers) as Executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "        # executor.map works like the map builtin, except that \n",
    "        # the DL function will be called concurrently from multiple threads\n",
    "        # It returns a generator that can be iterated over to retrieve\n",
    "        # the value returned by each function\n",
    "        return len(list(res)) # if any threaded calls raised an exception,\n",
    "        # we'll hit it here, when we transform the generator to a list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)  # call the previous main function,\n",
    "    # but pass the enhanced download many version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the Futures?\n",
    "Two classes named futures\n",
    "\n",
    "- concurrent.futures.Future\n",
    "- asyncio.Future\n",
    "\n",
    "Serve the same purpose:  either represents a deferred computation that may or may not have completed. \n",
    "\n",
    "We shouldn't create these. They are meantto be instantiated exclusively by the concurrency framework.\n",
    "\n",
    "Example of how they are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_many(cc_list):\n",
    "    cc_list = cc_list[:5]  # use only 5 countries for this example\n",
    "    with futures.ThreadPoolExecutor(max_works=3) as executor:\n",
    "        to_do = []\n",
    "        for cc in sorted(cc_list): # sorted to make it clear\n",
    "            # that results arrive out of order\n",
    "            future = executor.submit(download_one, cc) # schedule a the callable\n",
    "            # to be executed and returns a future representing this pending operation\n",
    "            to_do.append(future) # store each future\n",
    "            # so we can later retrieve them with 'as_completed'\n",
    "            msg = 'Scheduled for {}: {}'\n",
    "            print(msg.format(cc, future))\n",
    "        \n",
    "        results = []\n",
    "        for future in futures.as_completed(to_do): # as completed yields\n",
    "            # the futures as they are completd\n",
    "            res = future.result()\n",
    "            msg = '{} result {!r}'\n",
    "            print(msg.format(future, res))\n",
    "            results.append(res)\n",
    "        \n",
    "        return len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, strictly speaking, nothing so far has performed downloads in parallel.\n",
    "\n",
    "The concurrent.futures examples are limited by the GIL...\n",
    "\n",
    "However, the GIL is nearly harmless for IO-Bound processing.\n",
    "\n",
    "For CPU bound processing, the GIL is a problem.\n",
    "\n",
    "In that case, just change ThreadPoolExecutor --> ProcessPoolExecutor, and spawn processes instead of threads.\n",
    "\n",
    "Can't spawn more processes than CPU's on your machine. But this is an option to speed up tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
